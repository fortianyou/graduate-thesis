
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
%\secretcontent{绝密}

\ctitle{分布式流式主题模型的设计与实现}
% 根据自己的情况选，不用这样复杂
\makeatletter

\makeatother

\cdegree{工学硕士}
\cdepartment[计算所]{中国科学院计算技术研究所}
\cmajor{计算机软件与理论}
\cauthor{郭天佑}
\csupervisor{郭嘉丰\hspace{1em}研究员}
\csupervisorplace{中国科学院计算技术研究所}
% 如果没有副指导老师或者联合指导老师，把下面两行相应的删除即可。

% 日期自动生成，如果你要自己写就改这个cdate
%\cdate{\CJKdigits{\the\year}年\CJKnumber{\the\month}月}
\cdate{二〇一七年五月}

% 博士后部分
% \cfirstdiscipline{计算机科学与技术}
% \cseconddiscipline{系统结构}
% \postdoctordate{2009年7月——2011年7月}

\etitle{The Design and Implementation of\\ Distributed Stream Topic Model}
% 这块比较复杂，需要分情况讨论：
% 1. 学术型硕士
%    \edegree：必须为Master of Arts或Master of Science（注意大小写）
%              “哲学、文学、历史学、法学、教育学、艺术学门类，公共管理学科
%               填写Master of Arts，其它填写Master of Science”
%    \emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”
% 2. 学术型博士
%    \edegree：Doctor of Philosophy（注意大小写）
%    \emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”

\edegree{Master of Science}
\eauthor{Guo Tianyou}
\edepartment{Institute of Computing Technology\\Chinese Academy of Sciences}
\emajor{Computer Software and Theory}
\esupervisor{Guo Jiafeng}

% 这个日期也会自动生成，你要改么？
\edate{May, 2017}

% 定义中英文摘要和关键字
\begin{cabstract}
当今互联网上的数据正呈现出越来越快的增长趋势。
许多数据都具有无限、实时、突发等主要特性，特别是社交网络数据。
人们通常形象地将这类数据称为流式数据。

在社交网络以及其它文本挖掘技术的主要应用领域，主题模型作为一种能够挖掘文本语义的技术受到了青睐。
因此，在流式数据上训练主题模型具有一定的研究意义。
流式机器学习的主要挑战在于，根据流式数据的特性，算法必须满足使用内存大小固定，高效实时，并且能够克服数据变动带来的对模型训练的影响。
传统的批量学习并不满足上述要求。但是，目前绝大多数主题模型的高效实现都采用了在静态数据上的批量学习方法。

本文发现流式主题模型的设计与实现的主要难题在于：(1) 海量参数的分布式存储与并行更新同步困难；
(2) 流式学习系统对算法实时性的要求极高；
(3) 在社交网络等类似的数据环境下，不断会有新词出现，词表是动态增长的。

为了解决上述难题，本文介绍了如何设计与实现高效的分布式流式主题模型。
首先，本文提出了两种针对流式数据的主题模型框架，
在线流式主题模型和增量流式主题模型。
这两种模型能够有效地克服流式数据的无限性，
不仅算法能够动态地更新模型，而且具有概念迁移的能力。
然后，本文又采用了 Metropolis-Hastings 和 Alias Table 技术，
使得每次采样的复杂度降低到了 O(1)，保证了系统对算法实时性的要求。
最后，本文从算法实现的角度出发设计了稠密和稀疏并存的参数数据结构以及引入了几种简单有效的实现优化方法。
本文的算法在运行过程中只消耗固定的内存，大大降低了内存的浪费，提升了算法的运行速度。

\end{cabstract}

\ckeywords{流式学习, 主题模型, Metropolis-Hastings, 参数服务器}

\begin{eabstract}
Nowadays, the generation of data on the Internet shows growing trend. 
Many of the data are unlimited, real-time, and rapid, especially in social network. 
These data are called stream data.

In the domain of text mining application, such as social network, topic model has been favored as a key technology of mining semantics.
Train topic model with stream data is interesting and a tough task.
Stream learning is confronted with a few great challenges. According to the features of stream data, 
Stream learning system required algorithm to be fixed memory consumption, efficient and real-time, trained against multivate data distribution.
However, the traditional batch learning does not meet these requirements.
And the most efficient implementations of topic model usually trained by batch leanring process with static data.

In this paper, we found the main troubles in the design and implementation of distributed stream topic model are:
(1) it's hard to distributed store and parallel update massive parameters;
(2) the requirements of efficiency and real-time is significant to stream learning system;
(3) new words would apear at any time in scenarios like social network.

In order to solve the problems addressed above, we introduced how to design and implement distributed stream topic model in this paper.
First, we introduced two stream topic model framework, i.e., online stream topic model and incremental stream topic model.
These models solved the problem of infinty and volatility of stream data, and could capture the evaluation of topics upon stream data.
Second, we applied an efficient sampling strategy that take the advantage of metropolis-hastings and alias table.
We sample each token with complexity O(1) finally, witch is significant effective than original sampling method.
Finally, we designed a dense-sparse mixture parameter datastructure that greatly reduce the running time of the application.
Also we have used some other effective implementation optimization methods.
\end{eabstract}

\ekeywords{Stream Learning, Topic Model, Metropolis-Hastings, Parameter Server}
